# Text Classification with XLNet

This repository contains a Jupyter notebook includes data cleaning, dataset preparation, tokenization, HuggingFace Datasets, model fine-tuning, and accuracy evaluation using Trainer API.

---

## ðŸš€ Highlights / Features

## ðŸ”¹ Data preprocessing

âœ¨ Cleaning raw text

âœ¨ Removing unwanted patterns (emojis, mentions, URLs)

âœ¨Handling whitespace, special characters, and noise

## ðŸ”¹ Dataset balancing

âœ¨ Addressing class imbalance

âœ¨ Undersampling based on smallest label count

âœ¨ Ensuring equal representation of each class


## ðŸ”¹ Trainâ€“Validationâ€“Test splitting

âœ¨Creating separate datasets for training, tuning, and evaluating

âœ¨ Ensuring reproducibility using random_state

## ðŸ”¹ Creating HuggingFace Datasets

âœ¨ Converting Pandas DataFrames â†’ Dataset objects

âœ¨ Building a DatasetDict for train/test organization

## ðŸ”¹ Tokenization

âœ¨ How XLNet tokenizes text

Understanding: 
-- input_ids
-- attention_mask
-- token truncation (max_length)
-- padding (max_length and batch padding)

## ðŸ”¹ Model Fine-Tuning

âœ¨ Loading XLNetForSequenceClassification

âœ¨ Defining label mappings (num_labels, id2label)

âœ¨ Training using the Trainer API

## ðŸ”¹ Evaluation

âœ¨ Using HuggingFace evaluate library

âœ¨ Understanding logits, predictions, accuracy

âœ¨ Using compute_metrics to integrate evaluation into training

## ðŸ”¹ Debugging & Experimentation

âœ¨ Creating smaller subsets for faster testing

âœ¨ How .shuffle() and .select() help debug models quickly
